writer:
  logdir: runs/transfer_learning/cnn_dnn2/unfreeze_dnn3

run: optimizer

data:
  dataConfigPath: datasets/data_config.yaml
  trainDatasets:
    - lz2_lxy256
    - lz2_lxy128
    - lz2_lxy64
    - lz2_lxy32
    - lz2_lxy16
  batchSize: 128

training:
  epochs: 10000
  eval_epochs: 200
  model:
    name: cnn_dnn2
    stateDictPath: runs/cnn_dnn2/cosine_annealing/lz2_lxy16/model.pt
    freezeChildren:
      - 0
      - 1
      - 4
      - 5
  loss: mse
  optimizer:
    name: adam
    lr: 0.001
    betas: 0.9, 0.999
  lrScheduler:
    name: cosineAnnealingWarmRestarts
    T0: 2000
    TMult: 1
    etaMin: 0
    lastEpoch: -1
